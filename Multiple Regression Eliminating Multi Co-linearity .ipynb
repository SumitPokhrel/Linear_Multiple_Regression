{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two most important resources for Multiple Regression \n",
    "<br> https://www.youtube.com/watch?v=fTfMdCQJz4s for lecture \n",
    "<br> https://www.youtube.com/watch?time_continue=1553&v=NUXdtN1W1FE for python tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "import numpy as np # numerical computation \n",
    "import matplotlib.pyplot as plt # 2D plotting library  \n",
    "import pandas as pd # for dataframe, 2 D data with rows and columns \n",
    "import seaborn as sns # Seaborn is a library for making statistical graphics in Python\n",
    "# It is built on top of matplotlib and closely integrated with pandas data structures \n",
    "%matplotlib inline\n",
    "# The output of plotting commands is displayed inline within frontends like the Jupyter notebook, \n",
    "# directly below the code cell that produced it. The resulting plots will then also be stored in the notebook document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset \n",
    "companies = pd.read_csv('1000_Companies.csv')\n",
    "companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " ...\n",
      " [100275.47 241926.31 227142.82 'California']\n",
      " [128456.23 321652.14 281692.32 'California']\n",
      " [161181.72 270939.86 295442.17 'New York']]\n"
     ]
    }
   ],
   "source": [
    "# Extracting the Independent and Dependent variables\n",
    "# By convention X should be uppercase and y should be lowercase \n",
    "X = companies.iloc[:, 0:4].values # all rows, columns 0,1,2,3\n",
    "y = companies.iloc[:, 4].values # all rows, fifth column (starts from 0(R&D Spend))\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582434</td>\n",
       "      <td>0.978407</td>\n",
       "      <td>0.945245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administration</th>\n",
       "      <td>0.582434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520465</td>\n",
       "      <td>0.741560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing Spend</th>\n",
       "      <td>0.978407</td>\n",
       "      <td>0.520465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profit</th>\n",
       "      <td>0.945245</td>\n",
       "      <td>0.741560</td>\n",
       "      <td>0.917270</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 R&D Spend  Administration  Marketing Spend    Profit\n",
       "R&D Spend         1.000000        0.582434         0.978407  0.945245\n",
       "Administration    0.582434        1.000000         0.520465  0.741560\n",
       "Marketing Spend   0.978407        0.520465         1.000000  0.917270\n",
       "Profit            0.945245        0.741560         0.917270  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the Correlation Matrix\n",
    "companies.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that Marketing Spend and R&D Spend are extremly correlated (0.978). This will cause multi colinearity. We need to eliminate one of the independent variables. Let's eliminate Marketing Spend (0.917) and keep R&D Spend (0.945). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136897.8 471784.1 'New York']\n",
      " [151377.59 443898.53 'California']\n",
      " [101145.55 407934.54 'Florida']\n",
      " ...\n",
      " [241926.31 227142.82 'California']\n",
      " [321652.14 281692.32 'California']\n",
      " [270939.86 295442.17 'New York']]\n"
     ]
    }
   ],
   "source": [
    "X = companies.iloc[:, 1:4].values # Eliminating R&D Spend \n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136897.8 471784.1 2]\n",
      " [151377.59 443898.53 0]\n",
      " [101145.55 407934.54 1]\n",
      " ...\n",
      " [241926.31 227142.82 0]\n",
      " [321652.14 281692.32 0]\n",
      " [270939.86 295442.17 2]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data of state (New York, California and Florida) into integers (0, 1 and 2) using LabelEncoder \n",
    "# LabelEncoder encodes the labels between 0 and n-1 classes \n",
    "# It help transform non-numerical labels to numerical labels\n",
    "# It also helps to prepare the data for OneHotEncoding \n",
    "# Since OneHotEncoding takes only integer labels \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder() # labelencoder object of class LabelEncoder \n",
    "X[:, 2] = labelencoder.fit_transform(X[:, 2]) # transforming into New York=0, California=1, Florida=2\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 1.3689780e+05 4.7178410e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5137759e+05 4.4389853e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0114555e+05 4.0793454e+05]\n",
      " ...\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4192631e+05 2.2714282e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2165214e+05 2.8169232e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 2.7093986e+05 2.9544217e+05]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the integer labels into binary labels using OneHotEncoder \n",
    "# (New York, California and Florida) into integers (0, 1 and 2) using LabelEncoder\n",
    "# and integers (0, 1 and 2) into binary (1,0), (0,1) and (0,0) using OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features =[2]) # categorical_features = column of dataframe that needs to be HotEncoded \n",
    "# Since 3rd (0,1,2) column has label encoded data in the dataFrame \n",
    "# Unlike labelEncoder, we have to give the entire dataFrame as a parameter to OneHotEncoder \n",
    "X = onehotencoder.fit_transform(X).toarray() # transform the encoded data to an array\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 1.0000000e+00 1.3689780e+05 4.7178410e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.5137759e+05 4.4389853e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.0114555e+05 4.0793454e+05]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 2.4192631e+05 2.2714282e+05]\n",
      " [0.0000000e+00 0.0000000e+00 3.2165214e+05 2.8169232e+05]\n",
      " [0.0000000e+00 1.0000000e+00 2.7093986e+05 2.9544217e+05]]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoder automatically generates 1 extra dummy variable \n",
    "# We need only two dummy variables (0,1) for 3 types of categorical data (n-1), where n = no of categories \n",
    "# New York = 1, 0 California = 0, 1 Florida = 0, 0 \n",
    "X = X[:, 1:] # all rows, 2nd to last column (0 is the 1st column)\n",
    "# All this is doing is removing the first column \n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "# Convention --> (X,y) X_train, X_test, y_train, y_test \n",
    "# test_size = 0.2, 20% of the total data would be used for testing, rest for trianing \n",
    "# random_state:===================================================================================================== \n",
    "# If you don't specify the random_state in your code, then every time you run(execute) your code a new \n",
    "# random value is generated and the train and test datasets would have different values each time.\n",
    "# However, if a fixed value is assigned like random_state = 42 (or 0) then no matter how many times\n",
    "# you execute your code the result would be the same .i.e, same values in train and test datasets.\n",
    "# In practice I would say, you should set the random_state to some fixed number while you test stuff, \n",
    "# but then remove it in production if you really need a random (and not a fixed) split.\n",
    "# =================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training Set \n",
    "from sklearn.linear_model import LinearRegression \n",
    "regressor = LinearRegression() # regressor object of the class LinearRegression \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 90565.4549183   89231.66013825  95558.1615789  173980.70753522\n",
      "  84392.40760654 110960.02030434 169853.27349786  92211.50361802\n",
      " 163806.49460484  54194.35845003  68223.34420283 149414.20662372\n",
      " 126880.09350258  60777.09313745 176374.873465    76473.57865297\n",
      " 117801.00551914 163717.67368519 164505.66820023 180897.36578723\n",
      " 101542.77105289  86534.69207536 179176.54723885  85043.09150246\n",
      " 105448.72374492 101758.7541275   41156.33974605  58440.90914855\n",
      "  70127.08647148 227178.56810887 120276.37402309 112021.1671163\n",
      " 102074.21108737 137081.85170533  65308.13393229 109216.7567128\n",
      " 184756.89248794 169834.94778712 172966.72131045 117236.93367575\n",
      "  97421.45834873 164576.37223589 108107.91915771  51232.14223946\n",
      " 116104.59322756  60087.11249188 157092.96939586  78960.6347705\n",
      " 158375.5611409  130409.52059342 182979.83473803 172932.30629085\n",
      "  94434.21503433  79432.43725437 179603.02250807  84751.6038107\n",
      " 141915.91326953 169696.51197795  85324.97274627 105810.34725851\n",
      " 140702.15163224  54181.83142883 141482.1657631  138940.33064436\n",
      "  98883.83472993 113241.42536412 126789.28441192 151616.83641876\n",
      "  60380.7452556  172615.85529752 124638.91553484 168111.05417926\n",
      "  91420.57739619 155563.66005787  85201.73670294  78979.16534656\n",
      " 119919.63222533  94143.63053114 138721.40375899 143205.43861381\n",
      " 169547.03616817 139760.57172764 106849.51512309 154979.59754219\n",
      " 139775.52616235 110569.70282606  70886.73668928  89025.85438611\n",
      " 139810.09591187 148040.18489125 157271.82388357  59989.74296711\n",
      "  94463.43908642 112321.4511306   58122.77932575 107871.89521594\n",
      " 146270.6816018  151625.23039093 166947.50140389 118893.27370929\n",
      " 120261.26496255 138129.41354207 156891.57908863 121433.89631925\n",
      "  87991.72275913 104639.33072797  96055.76666788 177298.05063464\n",
      " 180706.97827626 110235.62454931 164382.47257265 166878.82585092\n",
      " 157355.76308739 173770.08384819 169217.37347594  53894.91382914\n",
      " 175811.64113332 105200.26348725  83639.6271715  138660.8128935\n",
      " 143259.78062885 160284.33978676 168093.20838498 119955.72609572\n",
      " 157547.08067575 110542.99689277 168773.18011393  62168.80594494\n",
      " 158301.07375918 157452.44792735 173504.8358188  155685.37201587\n",
      " 104185.43795894  86568.1130615  141247.97526242 165098.31976521\n",
      " 120670.88857503 176785.13863016 100445.72575051  82439.07737272\n",
      " 177479.51405051 102303.51990775  71769.62291487  91081.52669832\n",
      "  62711.73827344  70209.19223422  73320.75643478 175788.13810061\n",
      "  89880.29208222 150915.5614591   92783.75085417  63159.98225214\n",
      " 171799.34487735  62298.91178169 167461.14577041 165552.58567094\n",
      " 163949.12745213 102074.14720235 180433.18168439  74227.30035447\n",
      "  92010.04942577 135562.76981614  66306.85640213  73010.2451113\n",
      "  62082.19390306 182400.6538341  174573.3186489  158241.32219723\n",
      " 141075.74519081 154038.48390852  60072.68813036  90774.24516423\n",
      " 152350.46548504 166856.78312259  73704.4226767  115664.75156506\n",
      "  80473.22011771 149360.54932193 117059.04640124 130084.89410324\n",
      " 172859.27910945 298242.96579888 145813.43116673 150160.49041269\n",
      "  86361.55860703  70573.42467597  70700.17297565  70261.38923162\n",
      " 120834.63393365  90521.65185753 165317.33732033 125510.20492322\n",
      "  68543.83750437 144098.78726518 118691.81951704 165012.01696435\n",
      " 167108.60094223 146536.14814205 141111.83902566 109507.0318247 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results \n",
    "y_pred = regressor.predict(X_test)\n",
    "print (y_pred)\n",
    "y_pred.size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.46244030e+03 -6.16268772e+02  1.04077565e+00  3.55369298e-01]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Coefficeints \n",
    "print (regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on number of coeffients and independent variables \n",
    "Remember there are 4 coefficients and one intercept. \n",
    "Since Marketing Spend is already eliminated \n",
    "<br> y   =  m1x1 + m2x2 + m3x3 + m4x4  + C \n",
    "<br> Profit = R&D Spend, Administration, State (3 different states) \n",
    "<br> We have three different states but we need only 2 coefficients ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-88119.45034079812\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Intercept \n",
    "print (regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982282549585726"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the R squared value \n",
    "from sklearn.metrics import r2_score \n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Statsmodels and see the multiple regression summary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y_train</td>     <th>  R-squared:         </th> <td>   0.946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3480.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 08 Aug 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:09:58</td>     <th>  Log-Likelihood:    </th> <td> -8481.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>1.697e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   795</td>      <th>  BIC:               </th> <td>1.700e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>-8.812e+04</td> <td> 3658.415</td> <td>  -24.087</td> <td> 0.000</td> <td>-9.53e+04</td> <td>-8.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[0]</th> <td>-1462.4403</td> <td>  841.422</td> <td>   -1.738</td> <td> 0.083</td> <td>-3114.111</td> <td>  189.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[1]</th> <td> -616.2688</td> <td>  841.847</td> <td>   -0.732</td> <td> 0.464</td> <td>-2268.775</td> <td> 1036.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[2]</th> <td>    1.0408</td> <td>    0.033</td> <td>   31.869</td> <td> 0.000</td> <td>    0.977</td> <td>    1.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[3]</th> <td>    0.3554</td> <td>    0.004</td> <td>   80.273</td> <td> 0.000</td> <td>    0.347</td> <td>    0.364</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1073.779</td> <th>  Durbin-Watson:     </th>  <td>   1.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>597476.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 6.564</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>136.237</td> <th>  Cond. No.          </th>  <td>2.86e+06</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.86e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                y_train   R-squared:                       0.946\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     3480.\n",
       "Date:                Wed, 08 Aug 2018   Prob (F-statistic):               0.00\n",
       "Time:                        09:09:58   Log-Likelihood:                -8481.2\n",
       "No. Observations:                 800   AIC:                         1.697e+04\n",
       "Df Residuals:                     795   BIC:                         1.700e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept  -8.812e+04   3658.415    -24.087      0.000   -9.53e+04   -8.09e+04\n",
       "X_train[0] -1462.4403    841.422     -1.738      0.083   -3114.111     189.231\n",
       "X_train[1]  -616.2688    841.847     -0.732      0.464   -2268.775    1036.238\n",
       "X_train[2]     1.0408      0.033     31.869      0.000       0.977       1.105\n",
       "X_train[3]     0.3554      0.004     80.273      0.000       0.347       0.364\n",
       "==============================================================================\n",
       "Omnibus:                     1073.779   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           597476.615\n",
       "Skew:                           6.564   Prob(JB):                         0.00\n",
       "Kurtosis:                     136.237   Cond. No.                     2.86e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.86e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf \n",
    "df = pd.DataFrame(X_train, y_train) # Statsmodels takes only dataFrame \n",
    "reg = smf.ols(formula ='y_train~X_train', data=df).fit() \n",
    "# ols -->ordinary least squares or linear regression \n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
